{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317d9973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: dataset/test/goi cuon/823.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/610.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/348.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/360.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/758.jpg, Prediction: goi_cuon (score 0.50)\n",
      "File: dataset/test/goi cuon/770.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/764.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/765.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/413.jpg, Prediction: mi_quang (score 0.27)\n",
      "File: dataset/test/goi cuon/361.jpg, Prediction: goi_cuon (score 0.50)\n",
      "File: dataset/test/goi cuon/89.jpg, Prediction: goi_cuon (score 0.70)\n",
      "File: dataset/test/goi cuon/822.jpg, Prediction: pho (score 0.51)\n",
      "File: dataset/test/goi cuon/149.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/405.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/203.jpg, Prediction: goi_cuon (score 0.50)\n",
      "File: dataset/test/goi cuon/571.jpg, Prediction: goi_cuon (score 0.30)\n",
      "File: dataset/test/goi cuon/767.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/376.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/389.jpg, Prediction: goi_cuon (score 0.50)\n",
      "File: dataset/test/goi cuon/174.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/61.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/835.jpg, Prediction: goi_cuon (score 0.80)\n",
      "File: dataset/test/goi cuon/616.jpg, Prediction: goi_cuon (score 0.50)\n",
      "File: dataset/test/goi cuon/206.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/762.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/788.jpg, Prediction: goi_cuon (score 0.70)\n",
      "File: dataset/test/goi cuon/561.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/198.jpg, Prediction: goi_cuon (score 0.90)\n",
      "File: dataset/test/goi cuon/66.jpg, Prediction: goi_cuon (score 0.80)\n",
      "File: dataset/test/goi cuon/167.jpg, Prediction: goi_cuon (score 0.40)\n",
      "File: dataset/test/goi cuon/601.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/615.jpg, Prediction: goi_cuon (score 0.30)\n",
      "File: dataset/test/goi cuon/173.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/629.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/417.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/588.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/205.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/239.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/589.jpg, Prediction: goi_cuon (score 0.90)\n",
      "File: dataset/test/goi cuon/370.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/416.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/172.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/73.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/840.jpg, Prediction: mi_quang (score 0.63)\n",
      "File: dataset/test/goi cuon/14.jpg, Prediction: pho (score 1.00)\n",
      "File: dataset/test/goi cuon/854.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/129.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/459.jpg, Prediction: goi_cuon (score 1.00)\n",
      "File: dataset/test/goi cuon/317.jpg, Prediction: goi_cuon (score 0.80)\n",
      "File: dataset/test/goi cuon/288.jpg, Prediction: com_tam (score 0.35)\n",
      "File: dataset/test/goi cuon/539.jpg, Prediction: goi_cuon (score 0.60)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 160\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m glob.glob(os.path.join(folder, \u001b[33m'\u001b[39m\u001b[33m*.jpg\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m    159\u001b[39m     img = cv2.imread(filename)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     scores, (pred, conf) = \u001b[43mclassify_dish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (score \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36mclassify_dish\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m    140\u001b[39m scores = {\u001b[33m'\u001b[39m\u001b[33mpho\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbun_bo\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmi_quang\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcom_tam\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgoi_cuon\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbanh_xeo\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m}\n\u001b[32m    141\u001b[39m scores.update(detect_pho_bunbo_miquang(img))\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m scores.update(\u001b[43mdetect_com_tam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    143\u001b[39m scores.update(detect_goi_cuon(img))\n\u001b[32m    144\u001b[39m scores.update(detect_banh_xeo(img))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mdetect_com_tam\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Detect eggs via Hough Circles (white circle with yellow center)\u001b[39;00m\n\u001b[32m     92\u001b[39m gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m circles = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHoughCircles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHOUGH_GRADIENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminDist\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mparam1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminRadius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxRadius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m egg_count = \u001b[38;5;28mlen\u001b[39m(circles[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m circles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Score as weighted sum; require at least one egg circle\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_noodle_features(img):\n",
    "    \"\"\"More robust noodle detection with adaptive thresholding\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Adaptive thresholding for light regions\n",
    "    adaptive_light = cv2.adaptiveThreshold(\n",
    "        l, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 51, 7)\n",
    "\n",
    "    # Yellow detection in normalized color space\n",
    "    mean_b = np.mean(b)\n",
    "    std_b = np.std(b)\n",
    "    yellow_mask = cv2.inRange(b, mean_b + std_b, 255)\n",
    "\n",
    "    combined = cv2.bitwise_or(adaptive_light, yellow_mask)\n",
    "\n",
    "    \"\"\"Segment bright/yellow noodle regions and return fraction of image area.\"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Threshold for white noodles (low saturation, high value)\n",
    "    lower_white = np.array([0, 0, 200]); upper_white = np.array([180, 30, 255])\n",
    "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    # Threshold for yellow noodles (Hue ~20-35)\n",
    "    lower_yellow = np.array([20, 100, 100]); upper_yellow = np.array([35, 255, 255])\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    # Combine and clean up\n",
    "    mask_noodle = cv2.bitwise_or(mask_white, mask_yellow)\n",
    "    mask_noodle = cv2.morphologyEx(mask_noodle, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))\n",
    "    # Compute total noodle-like area\n",
    "    contours, _ = cv2.findContours(mask_noodle, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    noodle_area = sum(cv2.contourArea(c) for c in contours)\n",
    "    area_score = noodle_area / (img.shape[0] * img.shape[1] + 1e-6)\n",
    "    return area_score, mask_noodle\n",
    "\n",
    "def detect_soup_type(img):\n",
    "    \"\"\"Sample soup color in the center: return 'light' for Pho, 'red' for Bun Bo, else 'other'.\"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    # Sample central region of image (assuming bowl roughly centered)\n",
    "    center = (slice(img.shape[0]//4, 3*img.shape[0]//4), slice(img.shape[1]//4, 3*img.shape[1]//4))\n",
    "    avg_h = np.mean(h[center]); avg_s = np.mean(s[center]); avg_v = np.mean(v[center])\n",
    "    # Light, low-saturation broth (Pho)\n",
    "    if avg_v > 150 and avg_s < 80:\n",
    "        return 'light'\n",
    "    # Dark red broth (Bun Bo Hue)\n",
    "    if (avg_h < 15 or avg_h > 165) and avg_s > 100:\n",
    "        return 'red'\n",
    "    return 'other'\n",
    "\n",
    "def detect_pho_bunbo_miquang(img):\n",
    "    \"\"\"Assign scores to Pho, Bun Bo Hue, Mi Quang based on noodle and soup features.\"\"\"\n",
    "    noodle_score, mask = detect_noodle_features(img)\n",
    "    scores = {'pho': 0.0, 'bun_bo': 0.0, 'mi_quang': 0.0}\n",
    "    # If noodles are present, decide based on broth color\n",
    "    if noodle_score > 0.01:\n",
    "        soup = detect_soup_type(img)\n",
    "        base = min(noodle_score * 10, 1.0)\n",
    "        if soup == 'light':\n",
    "            scores['pho'] = base\n",
    "        if soup == 'red':\n",
    "            scores['bun_bo'] = base\n",
    "        # Check yellow ratio within noodle mask for Mi Quang\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask_yellow = cv2.inRange(hsv, np.array([20,100,100]), np.array([35,255,255]))\n",
    "        yellow_count = cv2.countNonZero(mask_yellow & mask)\n",
    "        white_count = cv2.countNonZero(cv2.inRange(hsv, np.array([0,0,200]), np.array([180,30,255])) & mask)\n",
    "        if yellow_count + white_count > 0:\n",
    "            yellow_ratio = yellow_count / (yellow_count + white_count)\n",
    "            if yellow_ratio > 0.3:\n",
    "                scores['mi_quang'] = base * yellow_ratio\n",
    "    return scores\n",
    "\n",
    "def detect_com_tam(img):\n",
    "    \"\"\"Detect Com Tam by rice (white), ribs (brown), and egg.\"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # White rice and egg whites\n",
    "    mask_white = cv2.inRange(hsv, np.array([0,0,200]), np.array([180,60,255]))\n",
    "    # Brown pork ribs (dark orange-red)\n",
    "    mask_brown = cv2.inRange(hsv, np.array([0,100,20]), np.array([15,255,80]))\n",
    "    # Yellow yolk\n",
    "    mask_yellow = cv2.inRange(hsv, np.array([20,100,100]), np.array([35,255,255]))\n",
    "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "    mask_brown = cv2.morphologyEx(mask_brown, cv2.MORPH_CLOSE, np.ones((5,5),np.uint8))\n",
    "    # Area ratios\n",
    "    area_white = cv2.countNonZero(mask_white) / (img.shape[0]*img.shape[1] + 1e-6)\n",
    "    area_brown = cv2.countNonZero(mask_brown) / (img.shape[0]*img.shape[1] + 1e-6)\n",
    "    area_yolk  = cv2.countNonZero(mask_yellow)/ (img.shape[0]*img.shape[1] + 1e-6)\n",
    "    # Detect eggs via Hough Circles (white circle with yellow center)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.5, minDist=50,\n",
    "                               param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "    egg_count = len(circles[0]) if circles is not None else 0\n",
    "    # Score as weighted sum; require at least one egg circle\n",
    "    score = (0.6*area_white + 0.3*area_brown + 0.1*area_yolk) * (1 if egg_count>0 else 0)\n",
    "    return {'com_tam': float(min(score, 1.0))}\n",
    "\n",
    "def detect_goi_cuon(img):\n",
    "    \"\"\"Detect Goi Cuon by shrimp (red shapes) and cylindrical roll contours.\"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Threshold for shrimp pink/red (split in two hue ranges)\n",
    "    mask_red1 = cv2.inRange(hsv, np.array([0,120,50]), np.array([10,255,255]))\n",
    "    mask_red2 = cv2.inRange(hsv, np.array([160,120,50]), np.array([180,255,255]))\n",
    "    mask_shrimp = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "    # Count shrimp-like contours\n",
    "    cnts, _ = cv2.findContours(mask_shrimp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    shrimp_count = sum(1 for c in cnts if cv2.contourArea(c) > 100)\n",
    "    # Detect elongated roll shapes via edges\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    cnts2, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    roll_count = 0\n",
    "    for c in cnts2:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w>0 and h>0:\n",
    "            aspect = max(w,h) / min(w,h)\n",
    "            if 1.5 < aspect < 5.0 and cv2.contourArea(c) > 500:\n",
    "                roll_count += 1\n",
    "    # Combine counts into score (capped at 1.0)\n",
    "    score = (0.5*shrimp_count + 0.5*roll_count) / 5.0\n",
    "    return {'goi_cuon': float(min(score,1.0))}\n",
    "\n",
    "def detect_banh_xeo(img):\n",
    "    \"\"\"Detect Banh Xeo by large yellow region and green foliage.\"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Yellow crepe\n",
    "    mask_yellow = cv2.inRange(hsv, np.array([20,100,100]), np.array([35,255,255]))\n",
    "    cnts, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    yellow_area = sum(cv2.contourArea(c) for c in cnts if cv2.contourArea(c) > 1000)\n",
    "    # Green lettuce\n",
    "    mask_green = cv2.inRange(hsv, np.array([40,50,50]), np.array([80,255,255]))\n",
    "    green_area = cv2.countNonZero(mask_green)\n",
    "    score = 0.7*(yellow_area/(img.shape[0]*img.shape[1]+1e-6)) + 0.3*(green_area/(img.shape[0]*img.shape[1]+1e-6))\n",
    "    return {'banh_xeo': float(min(score,1.0))}\n",
    "\n",
    "def classify_dish(img):\n",
    "    \"\"\"Run all detectors and choose dish with highest confidence score.\"\"\"\n",
    "    scores = {'pho':0, 'bun_bo':0, 'mi_quang':0, 'com_tam':0, 'goi_cuon':0, 'banh_xeo':0}\n",
    "    scores.update(detect_pho_bunbo_miquang(img))\n",
    "    scores.update(detect_com_tam(img))\n",
    "    scores.update(detect_goi_cuon(img))\n",
    "    scores.update(detect_banh_xeo(img))\n",
    "    # Identify best match\n",
    "    best = max(scores, key=scores.get)\n",
    "    return scores, (best, scores[best])\n",
    "\n",
    "# Example usage:\n",
    "# img = cv2.imread('dish.jpg')\n",
    "# scores, (pred, conf) = classify_dish(img)\n",
    "# print(f\"Prediction: {pred} (score {conf:.2f})\")\n",
    "\n",
    "# usage for folder dataset/test/pho\n",
    "import os\n",
    "import glob\n",
    "folder = 'dataset/test/goi cuon'\n",
    "for filename in glob.glob(os.path.join(folder, '*.jpg')):\n",
    "    img = cv2.imread(filename)\n",
    "    scores, (pred, conf) = classify_dish(img)\n",
    "    print(f\"File: {filename}, Prediction: {pred} (score {conf:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
